name: Deploy LLM Inference Endpoint

on:
  push:
    branches: [main]

permissions:
  id-token: write
  contents: read

jobs:
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install Linting Tools
        run: |
          pip install flake8

      - name: Run Linting

        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics

  deploy:
    needs: quality-check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install SAM CLI
        run: pip install aws-sam-cli

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: SAM Build
        run: sam build --use-container

      - name: SAM Deploy
        run: |
          sam deploy --no-confirm-changeset \
            --no-fail-on-empty-changeset \
            --stack-name bedrock-api-stack \
            --capabilities CAPABILITY_IAM \
            --resolve-s3
